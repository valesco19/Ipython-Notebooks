{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cuDNN version 5110 on context None\n",
      "Mapped name None to device cuda0: GeForce GTX 965M (0000:01:00.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GpuElemwise{exp,no_inplace}(<GpuArrayType<None>(float32, vector)>), HostFromGpu(gpuarray)(GpuElemwise{exp,no_inplace}.0)]\n",
      "Looping 1000 times took 0.321571 seconds\n",
      "Result is [ 1.23178029  1.61879349  1.52278066 ...,  2.20771813  2.29967761\n",
      "  1.62323296]\n",
      "Used the cpu\n"
     ]
    }
   ],
   "source": [
    "from theano import function, config, shared, sandbox\n",
    "import theano.tensor as T\n",
    "import numpy\n",
    "import time\n",
    " \n",
    "vlen = 10 * 30 * 768  # 10 x #cores x # threads per core\n",
    "iters = 1000\n",
    " \n",
    "rng = numpy.random.RandomState(22)\n",
    "x = shared(numpy.asarray(rng.rand(vlen), config.floatX))\n",
    "f = function([], T.exp(x))\n",
    "print(f.maker.fgraph.toposort())\n",
    "t0 = time.time()\n",
    "for i in range(iters):\n",
    "    r = f()\n",
    "t1 = time.time()\n",
    "print(\"Looping %d times took %f seconds\" % (iters, t1 - t0))\n",
    "print(\"Result is %s\" % (r,))\n",
    "if numpy.any([isinstance(x.op, T.Elemwise) for x in f.maker.fgraph.toposort()]):\n",
    "    print('Used the cpu')\n",
    "else:\n",
    "    print('Used the gpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1000/1000 [==============================] - 1s - loss: 0.7339 - acc: 0.5030     \n",
      "Epoch 2/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.7224 - acc: 0.4920     \n",
      "Epoch 3/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.7082 - acc: 0.5170     \n",
      "Epoch 4/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.7093 - acc: 0.5320     \n",
      "Epoch 5/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.6983 - acc: 0.5320     \n",
      "Epoch 6/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.6862 - acc: 0.5490     \n",
      "Epoch 7/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.6826 - acc: 0.5520     \n",
      "Epoch 8/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.6726 - acc: 0.5690     \n",
      "Epoch 9/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.6747 - acc: 0.5830     \n",
      "Epoch 10/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.6630 - acc: 0.5980     \n",
      "Epoch 11/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.6554 - acc: 0.6170     \n",
      "Epoch 12/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.6609 - acc: 0.6060     \n",
      "Epoch 13/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.6516 - acc: 0.6270     \n",
      "Epoch 14/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.6384 - acc: 0.6370     \n",
      "Epoch 15/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.6345 - acc: 0.6410     \n",
      "Epoch 16/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.6309 - acc: 0.6520     \n",
      "Epoch 17/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.6256 - acc: 0.6690     \n",
      "Epoch 18/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.6180 - acc: 0.6760     \n",
      "Epoch 19/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.6237 - acc: 0.6500     \n",
      "Epoch 20/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.6092 - acc: 0.6830     \n",
      "Epoch 21/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.5984 - acc: 0.7220     \n",
      "Epoch 22/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.5961 - acc: 0.7060     \n",
      "Epoch 23/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.5911 - acc: 0.7210     \n",
      "Epoch 24/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.5894 - acc: 0.7280     \n",
      "Epoch 25/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.5815 - acc: 0.7350     \n",
      "Epoch 26/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.5793 - acc: 0.7220     \n",
      "Epoch 27/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.5730 - acc: 0.7300     \n",
      "Epoch 28/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.5767 - acc: 0.7280     \n",
      "Epoch 29/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.5655 - acc: 0.7360     \n",
      "Epoch 30/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.5609 - acc: 0.7560     \n",
      "Epoch 31/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.5594 - acc: 0.7490     \n",
      "Epoch 32/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.5539 - acc: 0.7680     \n",
      "Epoch 33/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.5508 - acc: 0.7650     \n",
      "Epoch 34/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.5441 - acc: 0.7680     \n",
      "Epoch 35/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.5462 - acc: 0.7730     \n",
      "Epoch 36/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.5425 - acc: 0.7540     \n",
      "Epoch 37/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.5355 - acc: 0.7820     \n",
      "Epoch 38/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.5340 - acc: 0.7760     \n",
      "Epoch 39/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.5305 - acc: 0.7720     \n",
      "Epoch 40/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.5219 - acc: 0.7820     \n",
      "Epoch 41/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.5220 - acc: 0.7840     \n",
      "Epoch 42/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.5174 - acc: 0.7970     \n",
      "Epoch 43/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.5238 - acc: 0.8020     \n",
      "Epoch 44/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.5103 - acc: 0.7970     \n",
      "Epoch 45/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.5162 - acc: 0.7950     \n",
      "Epoch 46/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.5076 - acc: 0.7840     \n",
      "Epoch 47/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.5073 - acc: 0.7950     \n",
      "Epoch 48/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.5062 - acc: 0.7830     \n",
      "Epoch 49/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.4995 - acc: 0.8060     \n",
      "Epoch 50/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.4978 - acc: 0.8150     \n",
      "Epoch 51/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.4970 - acc: 0.8090     \n",
      "Epoch 52/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.4972 - acc: 0.8000     \n",
      "Epoch 53/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.4930 - acc: 0.8080     \n",
      "Epoch 54/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.4830 - acc: 0.8190     \n",
      "Epoch 55/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.4891 - acc: 0.8080     \n",
      "Epoch 56/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.4809 - acc: 0.8300     \n",
      "Epoch 57/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.4823 - acc: 0.8330     \n",
      "Epoch 58/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.4758 - acc: 0.8340     \n",
      "Epoch 59/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.4791 - acc: 0.8210     \n",
      "Epoch 60/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.4697 - acc: 0.8330     \n",
      "Epoch 61/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.4694 - acc: 0.8260     \n",
      "Epoch 62/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.4719 - acc: 0.8320     \n",
      "Epoch 63/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 0.4601 - acc: 0.840 - 0s - loss: 0.4679 - acc: 0.8230     \n",
      "Epoch 64/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.4658 - acc: 0.8250     \n",
      "Epoch 65/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.4618 - acc: 0.8360     \n",
      "Epoch 66/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.4617 - acc: 0.8400     \n",
      "Epoch 67/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.4590 - acc: 0.8310     \n",
      "Epoch 68/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.4538 - acc: 0.8480     \n",
      "Epoch 69/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.4550 - acc: 0.8380     \n",
      "Epoch 70/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.4541 - acc: 0.8410     \n",
      "Epoch 71/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.4492 - acc: 0.8340     \n",
      "Epoch 72/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.4492 - acc: 0.8400     \n",
      "Epoch 73/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.4443 - acc: 0.8480     \n",
      "Epoch 74/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.4453 - acc: 0.8500     \n",
      "Epoch 75/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.4466 - acc: 0.8430     \n",
      "Epoch 76/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.4418 - acc: 0.8380     \n",
      "Epoch 77/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.4401 - acc: 0.8480     \n",
      "Epoch 78/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.4387 - acc: 0.8480     \n",
      "Epoch 79/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.4362 - acc: 0.8500     \n",
      "Epoch 80/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.4341 - acc: 0.8490     \n",
      "Epoch 81/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.4338 - acc: 0.8550     \n",
      "Epoch 82/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.4306 - acc: 0.8580     \n",
      "Epoch 83/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.4337 - acc: 0.8480     \n",
      "Epoch 84/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.4261 - acc: 0.8550     \n",
      "Epoch 85/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.4270 - acc: 0.8490     \n",
      "Epoch 86/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s - loss: 0.4257 - acc: 0.8670     \n",
      "Epoch 87/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.4222 - acc: 0.8590     \n",
      "Epoch 88/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.4207 - acc: 0.8600     \n",
      "Epoch 89/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.4187 - acc: 0.8620     \n",
      "Epoch 90/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.4197 - acc: 0.8550     \n",
      "Epoch 91/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.4183 - acc: 0.8670     \n",
      "Epoch 92/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.4158 - acc: 0.8750     \n",
      "Epoch 93/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.4134 - acc: 0.8760     \n",
      "Epoch 94/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.4143 - acc: 0.8600     \n",
      "Epoch 95/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.4073 - acc: 0.8670     \n",
      "Epoch 96/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.4079 - acc: 0.8700     \n",
      "Epoch 97/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.4093 - acc: 0.8680     \n",
      "Epoch 98/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.4028 - acc: 0.8740     \n",
      "Epoch 99/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.4078 - acc: 0.8630     \n",
      "Epoch 100/100\n",
      "1000/1000 [==============================] - 0s - loss: 0.3997 - acc: 0.8590     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2afdbeedf60>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    " \n",
    "# for a single-input model with 2 classes (binary):\n",
    " \n",
    "model = Sequential()\n",
    "model.add(Dense(1, input_dim=784, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    " \n",
    "# generate dummy data\n",
    "import numpy as np\n",
    "data = np.random.random((1000, 784))\n",
    "labels = np.random.randint(2, size=(1000, 1))\n",
    " \n",
    "# train the model, iterating on the data in batches\n",
    "# of 32 samples\n",
    "model.fit(data, labels, epochs=100, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
