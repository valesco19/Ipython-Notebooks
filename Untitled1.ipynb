{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input = K.placeholder(shape = (2, 4, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.utils import np_utils\n",
    "from sklearn import metrics\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing training data...\n",
      "Validation...\n",
      "------------------------------------------------------------\n",
      "Fold 0\n",
      "------------------------------------------------------------\n",
      "Building model...\n",
      "Training model...\n",
      "ROC: 0.798477145775\n",
      "------------------------------------------------------------\n",
      "Fold 1\n",
      "------------------------------------------------------------\n",
      "Building model...\n",
      "Training model...\n",
      "ROC: 0.800512728174\n",
      "------------------------------------------------------------\n",
      "Fold 2\n",
      "------------------------------------------------------------\n",
      "Building model...\n",
      "Training model...\n",
      "ROC: 0.810796552409\n",
      "------------------------------------------------------------\n",
      "Fold 3\n",
      "------------------------------------------------------------\n",
      "Building model...\n",
      "Training model...\n",
      "ROC: 0.777852721655\n",
      "Average ROC: 0.796909787003\n",
      "Generating submission...\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.utils import np_utils\n",
    "from sklearn import metrics\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "'''\n",
    "    This demonstrates how to reach a 0.80 ROC AUC score (local 4-fold validation)\n",
    "    in the Kaggle Nile virus prediction challenge. \n",
    "\n",
    "    The model trains in a few seconds on CPU.\n",
    "'''\n",
    "\n",
    "# let's define some utils\n",
    "\n",
    "def get_weather_data():\n",
    "    weather_dic = {}\n",
    "    fi = csv.reader(open(\"weather.csv\"))\n",
    "    weather_head = fi.__next__()\n",
    "    for line in fi:\n",
    "        if line[0] == '1':\n",
    "            continue\n",
    "        weather_dic[line[1]] = line\n",
    "    weather_indexes = dict([(weather_head[i], i) for i in range(len(weather_head))])\n",
    "    return weather_dic, weather_indexes\n",
    "\n",
    "def process_line(line, indexes, weather_dic, weather_indexes):\n",
    "    def get(name):\n",
    "        return line[indexes[name]]\n",
    "\n",
    "    date = get(\"Date\")\n",
    "    month = float(date.split('-')[1])\n",
    "    week = int(date.split('-')[1]) * 4 + int(date.split('-')[2]) / 7\n",
    "    latitude = float(get(\"Latitude\"))\n",
    "    longitude = float(get(\"Longitude\"))\n",
    "    tmax = float(weather_dic[date][weather_indexes[\"Tmax\"]])\n",
    "    tmin = float(weather_dic[date][weather_indexes[\"Tmin\"]])\n",
    "    tavg = float(weather_dic[date][weather_indexes[\"Tavg\"]])\n",
    "    dewpoint = float(weather_dic[date][weather_indexes[\"DewPoint\"]])\n",
    "    wetbulb = float(weather_dic[date][weather_indexes[\"WetBulb\"]])\n",
    "    pressure = float(weather_dic[date][weather_indexes[\"StnPressure\"]])\n",
    "\n",
    "    return [month, week, latitude, longitude, tmax, tmin, tavg, dewpoint, wetbulb, pressure]\n",
    "\n",
    "def preprocess_data(X, scaler=None):\n",
    "    if not scaler:\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(X)\n",
    "    X = scaler.transform(X)\n",
    "    return X, scaler\n",
    "\n",
    "def shuffle(X, y, seed=1337):\n",
    "    np.random.seed(seed)\n",
    "    shuffle = np.arange(len(y))\n",
    "    np.random.shuffle(shuffle)\n",
    "    X = X[shuffle]\n",
    "    y = y[shuffle]\n",
    "    return X, y\n",
    "\n",
    "def build_model(input_dim, output_dim):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(32, input_dim=input_dim))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(32))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(output_dim))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=\"adadelta\")\n",
    "    return model\n",
    "\n",
    "\n",
    "# now the actual script\n",
    "\n",
    "print(\"Processing training data...\")\n",
    "\n",
    "rows = []\n",
    "labels = []\n",
    "fi = csv.reader(open(\"train.csv\"))\n",
    "head = fi.__next__()\n",
    "indexes = dict([(head[i], i) for i in range(len(head))])\n",
    "weather_dic, weather_indexes = get_weather_data()\n",
    "for line in fi:\n",
    "    rows.append(process_line(line, indexes, weather_dic, weather_indexes))\n",
    "    labels.append(float(line[indexes[\"WnvPresent\"]]))\n",
    "\n",
    "X = np.array(rows)\n",
    "y = np.array(labels)\n",
    "\n",
    "X, y = shuffle(X, y)\n",
    "X, scaler = preprocess_data(X)\n",
    "Y = np_utils.to_categorical(y)\n",
    "\n",
    "input_dim = X.shape[1]\n",
    "output_dim = 2\n",
    "\n",
    "print(\"Validation...\")\n",
    "\n",
    "nb_folds = 4\n",
    "kfolds = KFold(len(y), nb_folds)\n",
    "av_roc = 0.\n",
    "f = 0\n",
    "for train, valid in kfolds:\n",
    "    print('---'*20)\n",
    "    print('Fold', f)\n",
    "    print('---'*20)\n",
    "    f += 1\n",
    "    X_train = X[train]\n",
    "    X_valid = X[valid]\n",
    "    Y_train = Y[train]\n",
    "    Y_valid = Y[valid]\n",
    "    y_valid = y[valid]\n",
    "\n",
    "    print(\"Building model...\")\n",
    "    model = build_model(input_dim, output_dim)\n",
    "\n",
    "    print(\"Training model...\")\n",
    "\n",
    "    model.fit(X_train, Y_train, nb_epoch=100, batch_size=16, validation_data=(X_valid, Y_valid), verbose=0)\n",
    "    valid_preds = model.predict_proba(X_valid, verbose=0)\n",
    "    valid_preds = valid_preds[:, 1]\n",
    "    roc = metrics.roc_auc_score(y_valid, valid_preds)\n",
    "    print(\"ROC:\", roc)\n",
    "    av_roc += roc\n",
    "\n",
    "print('Average ROC:', av_roc/nb_folds)\n",
    "\n",
    "print(\"Generating submission...\")\n",
    "\n",
    "model = build_model(input_dim, output_dim)\n",
    "model.fit(X, Y, nb_epoch=100, batch_size=16, verbose=0)\n",
    "\n",
    "fi = csv.reader(open(\"test.csv\"))\n",
    "head = fi.__next__()\n",
    "indexes = dict([(head[i], i) for i in range(len(head))])\n",
    "rows = []\n",
    "ids = []\n",
    "for line in fi:\n",
    "    rows.append(process_line(line, indexes, weather_dic, weather_indexes))\n",
    "    ids.append(line[0])\n",
    "X_test = np.array(rows)\n",
    "X_test, _ = preprocess_data(X_test, scaler)\n",
    "\n",
    "preds = model.predict_proba(X_test, verbose=0)\n",
    "\n",
    "fo = csv.writer(open(\"keras-nn.csv\", \"w\"), lineterminator=\"\\n\")\n",
    "fo.writerow([\"Id\",\"WnvPresent\"])\n",
    "\n",
    "for i, item in enumerate(ids):\n",
    "    fo.writerow([ids[i], preds[i][1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/valesco/.mozilla/firefox/yylupir9.default']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob, os\n",
    "glob.glob(os.path.expanduser('~/.mozilla/firefox/*.default'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "homeDir = os.environ['HOME']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fi = csv.reader(open(\"test.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pulp\n",
    "import pystan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
